\section{卷积神经网络}

\noindent\textbf{习题5-1} 1）证明公式（5.6）可以近似为离散信号序列x(t)关于t的二阶微分；2）对于二维卷积，设计一种滤波器来近似
实现对二维输入信号的二阶微分。

习题 5-1: 公式 (5.6)：
\[
x''(t) = x(t+1) + x(t-1) - 2x(t) \tag{5.6}
\]

证明：

对于 \(x\)：
\[
x'(t) = x(t+1) - x(t)
\]

\[
x''(t) = x'(t) - x'(t-1)
\]
\[
= [x(t+1) - x(t)] - [x(t) - x(t-1)]
\]
\[
= x(t+1) + x(t-1) - 2x(t)
\]

对于离散的函数来说，微分常常称为差分，在计算的时候又分为向前差分和向后差分。

对于二维的输入信号，由公式 (5.6) 得：
\[
\frac{\partial^2 f}{\partial x^2} = f(x+1, y) + f(x-1, y) - 2f(x, y)
\]
\[
\frac{\partial^2 f}{\partial y^2} = f(x, y+1) + f(x, y-1) - 2f(x, y)
\]

所以，二维的二阶微分为：
\[
\frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} = f(x+1, y) + f(x-1, y) + f(x, y+1) + f(x, y-1) - 4f(x, y)
\]

由此我们可以设计滤波器：
\[
\begin{bmatrix}
0 & 1 & 0 \\
1 & -4 & 1 \\
0 & 1 & 0
\end{bmatrix}
\]

也称为 Laplace 算子。


\noindent\textbf{习题5-2} 证明宽卷积具有交换性，即公式（5.13）.

\[
rot180(W) \tilde{\otimes} X
\]
\[
= rot180(W) \otimes \tilde{X}
\]
\[
= \tilde{X} \otimes rot180(W)
\]
\[
= X \tilde{\otimes} rot180(W)
\]
\[
= rot180(X) \tilde{\otimes} W
\]


\noindent\textbf{习题5-3} 分析卷积神经网络中用1X1的卷积核的作用。

\begin{enumerate}
\item 降维或升维，调整通道数
\item 降低计算复杂度，
\item 跨通道信息交互，其实就是不同通道之间的线性组合，这就是跨通道信息交互
\end{enumerate}

\noindent\textbf{习题5-4} 对于一个输入为100X100X256的特征映射组，使用3X3的卷积核，输出为100X100X256的特征
映射组的卷积层，求其时间和空间复杂度。如果引入一个1X1卷积核，先得到100X100X64的特征映射，再进行3X3的卷积，
得到100X100X256的特征映射，求其时间和空间复杂度。

（答案请自行查看插图，前两张为代码角度，后一张为直观角度）

\noindent\textbf{习题5-5} 对于一个二维卷积，输入为 $3 \times 3$，卷积核大小为 $2 \times 2$，试将卷积操作重写为仿射变换的形式。

解析：将 $3 \times 3$ 输入展开成 9 维向量。$3 \times 3$ 的输入，卷积核大小为 $2 \times 2$，一共做四次卷积操作。在对应的位置上填写卷积核的值。

\[
\begin{bmatrix}
w_{11} & w_{12} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
w_{21} & w_{22} & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & w_{11} & w_{12} & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & w_{21} & w_{22} & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & w_{11} & w_{12} & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & w_{21} & w_{22} & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & w_{11} & w_{12} & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & w_{21} & w_{22} & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & w_{11} & w_{12} & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & w_{21} & w_{22} & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & w_{11} & w_{12} & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & w_{21} & w_{22} & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & w_{11} & w_{12} & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & w_{21} & w_{22} & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & w_{11} & w_{12} \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & w_{21} & w_{22} \\
\end{bmatrix}
\cdot
\begin{bmatrix}
x_1 \\ x_2 \\ x_3 \\ x_4 \\ x_5 \\ x_6 \\ x_7 \\ x_8 \\ x_9
\end{bmatrix}
\]

\noindent\textbf{习题5-6} 计算函数 $y = \max(x_1, \cdots, x_D)$ 和函数 $y = \arg\max(x_1, \cdots, x_D)$ 的梯度。

\section*{max 和 argmax}

\begin{itemize}
    \item $y = f(t)$ 是一般常见的函数式，如果给定一个值，$f(t)$ 函数式会赋一个值给 $y$。
    \item $y = \max f(t)$ 代表：$y$ 是 $f(t)$ 函数所有值中的值最大的 output。
    \item $y = \arg\max f(t)$ 代表：$y$ 是 $f(t)$ 函数中，会产生最大 output 的那个参数。
\end{itemize}

例如：

假设有一个函数 $f(t)$，$t$ 的可能范围是 $\{0, 1, 2\}$，$f(t=0) = 10$，$f(t=1) = 20$，$f(t=2) = 7$，那么分别对应的 $y$ 如下：

\[
y = \max f(t) = 20
\]
\[
y = \arg\max f(t) = 1
\]

argmax 是不导的，argmax \((x_1, x_2, \lambda): 
\begin{cases} 
0 & x_1 > x_2 \\ 
1 & x_1 < x_2 
\end{cases}\)
并且只要 $\(x_1\)\neq\(x_2\)$ ，那么对 $\(x_1\)$ 和 $\(x_2\)$ 进行一个很微小的变化，argmax 值是不发生改变的。因此这个时候 argmax 的梯度对于 $\(x_1\)$ 和 $\(x_2\)$ 来说都是 0。当 $\(x_1 = x_2\)$ 时，梯度值有一个会突然从 0 变为 1。

max \((x_1, x_2)\) 虽在 \(x_1 = x_2\)处不可导，但是其他点处，函数的值是 \(x_1\) 或 \(x_2\)，并且 \(x_1\)、\(x_2\) 的微小移动是可以改变 max 的函数值的，因此对于 \(x_1\)、\(x_2\)的梯度要么是 \((0, 1)\)，要么是 \((1, 0)\)，可以看到梯度总是存在的，即训练最大的那个数对应的梯度。

这里的 $x_1$ 指的是 f_1(t)$，$x_d$ 指的是 $f_d(t)$


\noindent\textbf{习题5-7}  忽略激活函数，分析卷积网络中卷积层的前向计算和反向传播（公式 $(5.39)$）是一种转置关系。

解答：（请自行查看插图）

\noindent\textbf{习题5-8} 在空洞卷积中，当卷积核大小为 $K$，膨胀率为 $D$ 时，如何设置零填充 $P$ 的值以使得卷积为等宽卷积。

根据等宽卷积：

\[
\frac{(M - K' + 2P)}{S} + 1 = M, \quad \text{其中} S = 1,
\]

\[
K' = K + (K-1)(D-1),
\]
$
求得：

\[
P = \frac{(K-1)D}{2}.
\]



